{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13043799,"sourceType":"datasetVersion","datasetId":8259555}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:47:59.975866Z","iopub.execute_input":"2025-09-13T05:47:59.976074Z","iopub.status.idle":"2025-09-13T05:48:01.773157Z","shell.execute_reply.started":"2025-09-13T05:47:59.976039Z","shell.execute_reply":"2025-09-13T05:48:01.772456Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/my-images/bread.webp\n/kaggle/input/my-images/chair.jpeg\n/kaggle/input/my-images/tomatoes.webp\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade tensorflow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.xception import Xception\nfrom keras.utils import load_img, img_to_array\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:05:37.975265Z","iopub.execute_input":"2025-09-13T06:05:37.975993Z","iopub.status.idle":"2025-09-13T06:05:37.981172Z","shell.execute_reply.started":"2025-09-13T06:05:37.975970Z","shell.execute_reply":"2025-09-13T06:05:37.980411Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model = ResNet50(weights='imagenet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:57:11.959607Z","iopub.execute_input":"2025-09-13T05:57:11.959982Z","iopub.status.idle":"2025-09-13T05:57:13.278223Z","shell.execute_reply.started":"2025-09-13T05:57:11.959955Z","shell.execute_reply":"2025-09-13T05:57:13.277587Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"img_path = '/kaggle/input/my-images/bread.webp'\nimg = load_img(img_path, target_size=(224,224))\nx = img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:57:20.675174Z","iopub.execute_input":"2025-09-13T05:57:20.675753Z","iopub.status.idle":"2025-09-13T05:57:21.159962Z","shell.execute_reply.started":"2025-09-13T05:57:20.675689Z","shell.execute_reply":"2025-09-13T05:57:21.159220Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"preds = model.predict(x)\nprint(\"Predicted: \", decode_predictions(preds, top=3)[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:57:27.329987Z","iopub.execute_input":"2025-09-13T05:57:27.330677Z","iopub.status.idle":"2025-09-13T05:57:33.675682Z","shell.execute_reply.started":"2025-09-13T05:57:27.330653Z","shell.execute_reply":"2025-09-13T05:57:33.675024Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757743049.833482     102 service.cc:148] XLA service 0x7c2cd0002560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757743049.833558     102 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757743049.833565     102 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757743050.431432     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\nDownloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nPredicted:  [('n03637318', 'lampshade', 0.52013665), ('n03709823', 'mailbag', 0.090211116), ('n04599235', 'wool', 0.08607283)]\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1757743053.556179     102 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# VGG16 Pretrained Model","metadata":{"execution":{"iopub.status.busy":"2025-09-13T05:50:04.619430Z","iopub.execute_input":"2025-09-13T05:50:04.619981Z","iopub.status.idle":"2025-09-13T05:50:04.623004Z","shell.execute_reply.started":"2025-09-13T05:50:04.619957Z","shell.execute_reply":"2025-09-13T05:50:04.622420Z"}}},{"cell_type":"code","source":"model2 = VGG16(weights='imagenet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:57:43.143280Z","iopub.execute_input":"2025-09-13T05:57:43.143987Z","iopub.status.idle":"2025-09-13T05:57:45.395817Z","shell.execute_reply.started":"2025-09-13T05:57:43.143962Z","shell.execute_reply":"2025-09-13T05:57:45.395050Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"img_path = '/kaggle/input/my-images/tomatoes.webp'\nimg = load_img(img_path, target_size=(224,224))\nx = img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:59:33.950865Z","iopub.execute_input":"2025-09-13T05:59:33.951521Z","iopub.status.idle":"2025-09-13T05:59:33.982689Z","shell.execute_reply.started":"2025-09-13T05:59:33.951498Z","shell.execute_reply":"2025-09-13T05:59:33.981998Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"preds2 = model2.predict(x)\nprint(\"Predicted: \", decode_predictions(preds2, top=3)[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:59:34.827169Z","iopub.execute_input":"2025-09-13T05:59:34.827853Z","iopub.status.idle":"2025-09-13T05:59:34.920817Z","shell.execute_reply.started":"2025-09-13T05:59:34.827829Z","shell.execute_reply":"2025-09-13T05:59:34.920222Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\nPredicted:  [('n07745940', 'strawberry', 0.80626637), ('n07720875', 'bell_pepper', 0.18716379), ('n07718472', 'cucumber', 0.003559085)]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# VGG19 Pretrained Model","metadata":{}},{"cell_type":"code","source":"model3 = VGG19(weights='imagenet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:02:29.037579Z","iopub.execute_input":"2025-09-13T06:02:29.038266Z","iopub.status.idle":"2025-09-13T06:02:34.215806Z","shell.execute_reply.started":"2025-09-13T06:02:29.038240Z","shell.execute_reply":"2025-09-13T06:02:34.215183Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n\u001b[1m574710816/574710816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"img_path = '/kaggle/input/my-images/bread.webp'\nimg = load_img(img_path, target_size=(224,224))\nx = img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:03:44.346678Z","iopub.execute_input":"2025-09-13T06:03:44.346979Z","iopub.status.idle":"2025-09-13T06:03:44.571768Z","shell.execute_reply.started":"2025-09-13T06:03:44.346958Z","shell.execute_reply":"2025-09-13T06:03:44.571174Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"preds3 = model3.predict(x)\nprint(\"Predicted: \", decode_predictions(preds3, top=3)[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:03:45.439479Z","iopub.execute_input":"2025-09-13T06:03:45.440149Z","iopub.status.idle":"2025-09-13T06:03:45.538171Z","shell.execute_reply.started":"2025-09-13T06:03:45.440125Z","shell.execute_reply":"2025-09-13T06:03:45.537603Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\nPredicted:  [('n07615774', 'ice_lolly', 0.3336445), ('n03637318', 'lampshade', 0.18652256), ('n04131690', 'saltshaker', 0.09480345)]\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# XCeption Pretrained Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import preprocess_input\nmodel4 = Xception(weights='imagenet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:09:46.651635Z","iopub.execute_input":"2025-09-13T06:09:46.651915Z","iopub.status.idle":"2025-09-13T06:09:47.566952Z","shell.execute_reply.started":"2025-09-13T06:09:46.651894Z","shell.execute_reply":"2025-09-13T06:09:47.566358Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"img_path = '/kaggle/input/my-images/bread.webp'\nimg = load_img(img_path, target_size=(299,299))\nx = img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:10:45.984870Z","iopub.execute_input":"2025-09-13T06:10:45.985586Z","iopub.status.idle":"2025-09-13T06:10:46.200910Z","shell.execute_reply.started":"2025-09-13T06:10:45.985561Z","shell.execute_reply":"2025-09-13T06:10:46.200260Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"preds4 = model4.predict(x)\nprint(\"Predicted: \", decode_predictions(preds4, top=3)[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:10:47.346482Z","iopub.execute_input":"2025-09-13T06:10:47.346779Z","iopub.status.idle":"2025-09-13T06:10:47.760870Z","shell.execute_reply.started":"2025-09-13T06:10:47.346756Z","shell.execute_reply":"2025-09-13T06:10:47.760152Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\nPredicted:  [('n07684084', 'French_loaf', 0.8597019), ('n04442312', 'toaster', 0.062148318), ('n02808304', 'bath_towel', 0.003900263)]\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}